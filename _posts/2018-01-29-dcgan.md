---
layout: post
title:  "Deep Convolutional GANs"
date:   2018-01-27 14:00:00 +0900
categories: dlnd
fbcomments: true
---

Outline:

- [DCGAN Architecture](#dcgan-architecture)
- [Batch Normalization](#batch-normalization)


## DCGAN Architecture

* **DCGAN**
    - Use **deep convolutional networks** for the **generator** and the **discriminator**.
    - Otherwise it's the same as **GAN**
    - The **generator** is trying to fool the discriminator with fake images
        - That means we need to **upsample the input vector** to make a layer with the same shape as the real images.
        - In an **auto-encoder**, where we re-sized a layer with **nearest neighbor interpolation**
        - For this GAN model, to use **transposed convolutions**
    - The **discriminator** is trying to properly classify images as real or fake.

![dcgan-model.png]({{ "/assets/img/gan/dcgan-model.png" | absolute_url }}){: .center-image }{:width="600px"}

    
* **Transposed convolutions**
    - similar to the convolutions, but **flipped**
    - go from **narrow** and deep to **wide** and flat.
    ![transposed-conv.png]({{ "/assets/img/gan/transposed-conv.png" | absolute_url }}){: .center-image }{:width="400px"}
    - When you move the kernel 1 pixel in the input layer, the patch moves 2 pixels and the output layer.
    ![transposed-conv-move.png]({{ "/assets/img/gan/transposed-conv-move.png" | absolute_url }}){: .center-image }{:width="400px"}


* **DCGAN generator**
    - The first step is to connect the input vector **z** to a **fully connected layer**
    - then **reshape** the fully connected layer to **whatever depth** you have for this first layer.
    - Then we **build this stack of layers** by upsampling with **transposed convolution**.
    - The **final layer**, the output of the generator, convolutional layer.
        - The **size** of this layer is actually whatever the **size of your real images**.
    - There are **no max pool or fully connected layers** in the network, **just convolutions**.  
    - The **new layer size** depends on the **stride**.
    - In the generator we can use ReLU and **batch normalization** activations for each layer
        - Batch normalization **scales the layer inputs** to have a **mean of $$0$$ and variance of $$1$$**.
        - This helps the network **train faster**, and **reduces problems** due to **poor parameter initialization**.

![dcgan-generator]({{ "/assets/img/gan/dcgan-generator.png" | absolute_url }}){: .center-image }{:width="600px"}

* **DCGAN discriminator**
    - The discriminator is a **convolutional network**
        - with **one fully connected layer** at the end, used as the **sigmoid output**.
        - there are **no max pool layers**.
    - The **downsampling** is done completely with the **strided convolutional layers**.
    - The final convolutional layer is **flattened**, then connected to a single sigmoid unit.
    - Again, the layers have leaky ReLU activations and batch normalization on the inputs.

![dcgan-discriminator]({{ "/assets/img/gan/dcgan-discriminator.png" | absolute_url }}){: .center-image }{:width="600px"}
 
 
## Batch Normalization

* Batch normalization is a 
    - **technique** for **improving the performance** and **stability of neural networks**. 
* The idea is 
    - **to normalize the layer inputs** such that they have **a mean of zero and variance of one**, much like how we **standardize** the inputs to networks. 
* Batch normalization is **necessary** to make DCGANs work. 
* Scratch from Jupyter notebook
    - [Lesson](https://github.com/byam/dlnd/blob/master/5.GenerativeAdversarialNetworks/batch-norm/Batch_Normalization_Lesson.ipynb)
    - [Solutions](https://github.com/byam/dlnd/blob/master/5.GenerativeAdversarialNetworks/batch-norm/Batch_Normalization_Solutions.ipynb)